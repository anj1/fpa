[project]
name = "power-attention"
version = "0.9.13"
description = "Kernels for symmetric-power-based linear transformers"
authors = [
  { name = "Sean Zhang", email = "sean@manifest.com" },
]
classifiers = [
  "Programming Language :: Python :: 3",
  "License :: OSI Approved :: MIT License",
]
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
  'torch>=2.5',
  'einops'
]

[build-system]
requires = [
    "setuptools==69.5.1",
    "torch>=2.5",
    "numpy>=2.2",
    "ninja==1.11.1.3",
    "pybind11==2.13.6",
    "psutil",
    "build",
    "wheel"
]
build-backend = "setuptools.build_meta"

[tool.uv]
environments = [
    "sys_platform == 'linux'"
]

[dependency-groups]
benchmark = [
  "flash-attn",
  "matplotlib",
  "pandas"
]
dev = [
  "twine"
]
